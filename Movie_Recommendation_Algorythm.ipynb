{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9KGIwE7VbuvyP4cHU4bZK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akos1993/Akos1993/blob/main/Movie_Recommendation_Algorythm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Dummy Data to work with"
      ],
      "metadata": {
        "id": "dukG5Qes4ctS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgg6uWSz3Ybx",
        "outputId": "aa0f02dc-2605-4570-c390-50e7e0d397fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.1)\n",
            "Downloading faker-37.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.0.0\n",
            "Dummy data generated and saved to CSV files: users.csv, movies.csv, ratings.csv\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "!pip install faker\n",
        "from faker import Faker\n",
        "import csv\n",
        "\n",
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Generate Users data\n",
        "def generate_users(num_users=100):\n",
        "    users = []\n",
        "    for user_id in range(1, num_users + 1):\n",
        "        name = fake.first_name()\n",
        "        age = random.randint(18, 65)\n",
        "        gender = random.choice(['Male', 'Female'])\n",
        "        users.append([user_id, name, age, gender])\n",
        "    return users\n",
        "\n",
        "# Generate Movies data\n",
        "def generate_movies(num_movies=100):\n",
        "    genres = ['Sci-Fi', 'Action', 'Drama', 'Romance', 'Thriller', 'Comedy', 'Animation', 'Crime', 'Musical']\n",
        "    movies = []\n",
        "    for movie_id in range(1, num_movies + 1):\n",
        "        title = fake.sentence(nb_words=3).strip('.')\n",
        "        genre = random.choice(genres)\n",
        "        release_year = random.randint(1980, 2025)\n",
        "        movies.append([movie_id, title, genre, release_year])\n",
        "    return movies\n",
        "\n",
        "# Generate Ratings data\n",
        "def generate_ratings(num_ratings=100, num_users=100, num_movies=100):\n",
        "    ratings = []\n",
        "    for rating_id in range(1, num_ratings + 1):\n",
        "        user_id = random.randint(1, num_users)\n",
        "        movie_id = random.randint(1, num_movies)\n",
        "        rating = random.randint(1, 5)\n",
        "        timestamp = fake.date_time_this_decade()\n",
        "        ratings.append([rating_id, user_id, movie_id, rating, timestamp])\n",
        "    return ratings\n",
        "\n",
        "# Write data to CSV files\n",
        "def write_to_csv(filename, data, headers):\n",
        "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(headers)\n",
        "        writer.writerows(data)\n",
        "\n",
        "# Generate and save Users data\n",
        "users = generate_users()\n",
        "write_to_csv('users.csv', users, ['UserID', 'Name', 'Age', 'Gender'])\n",
        "\n",
        "# Generate and save Movies data\n",
        "movies = generate_movies()\n",
        "write_to_csv('movies.csv', movies, ['MovieID', 'Title', 'Genre', 'ReleaseYear'])\n",
        "\n",
        "# Generate and save Ratings data\n",
        "ratings = generate_ratings()\n",
        "write_to_csv('ratings.csv', ratings, ['RatingID', 'UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
        "\n",
        "print(\"Dummy data generated and saved to CSV files: users.csv, movies.csv, ratings.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Install Pandas library for manipulating data"
      ],
      "metadata": {
        "id": "E3SV9sfV4yX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slWBSIH64mGS",
        "outputId": "068c2a07-0b56-410a-8f78-140c71212712"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clear data"
      ],
      "metadata": {
        "id": "gQ_4RM24FlEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def clean_data(file_path, drop_duplicates=True, fill_missing=None):\n",
        "    \"\"\"\n",
        "    Cleans a dataset by removing duplicates and dealing with incomplete data.\n",
        "\n",
        "    Parameters:\n",
        "        file_path (str): Path to the CSV file to be cleaned.\n",
        "        drop_duplicates (bool): Whether to drop duplicate rows. Default is True.\n",
        "        fill_missing (dict): A dictionary specifying column names and values to fill missing data.\n",
        "                             Example: {'Age': 25, 'Rating': 3}\n",
        "                             If None, drops rows with missing data. Default is None.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A cleaned pandas DataFrame.\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Remove duplicates\n",
        "    if drop_duplicates:\n",
        "        df = df.drop_duplicates()\n",
        "\n",
        "    # Handle missing data\n",
        "    if fill_missing:\n",
        "        df = df.fillna(fill_missing)  # Fill missing values with provided dictionary\n",
        "    else:\n",
        "        df = df.dropna()  # Drop rows with missing values\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage for users.csv\n",
        "cleaned_users = clean_data(\n",
        "    file_path='users.csv',\n",
        "    drop_duplicates=True,\n",
        "    fill_missing={'Age': 25, 'Gender': 'Unknown'}  # Fill missing 'Age' with 25 and 'Gender' with 'Unknown'\n",
        ")\n",
        "\n",
        "# Example usage for movies.csv\n",
        "cleaned_movies = clean_data(\n",
        "    file_path='movies.csv',\n",
        "    drop_duplicates=True,\n",
        "    fill_missing={'Genre': 'Unknown', 'ReleaseYear': 2000}  # Fill missing 'Genre' and 'ReleaseYear'\n",
        ")\n",
        "\n",
        "# Example usage for ratings.csv\n",
        "cleaned_ratings = clean_data(\n",
        "    file_path='ratings.csv',\n",
        "    drop_duplicates=True,\n",
        "    fill_missing={'Rating': 3}  # Fill missing 'Rating' with 3\n",
        ")\n",
        "\n",
        "# Display cleaned data samples\n",
        "print(\"Cleaned Users Data:\")\n",
        "print(cleaned_users.head())\n",
        "\n",
        "print(\"\\nCleaned Movies Data:\")\n",
        "print(cleaned_movies.head())\n",
        "\n",
        "print(\"\\nCleaned Ratings Data:\")\n",
        "print(cleaned_ratings.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9CBBU0BB5tA",
        "outputId": "0252c870-214e-45e6-8193-99eda86306a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Users Data:\n",
            "   UserID     Name  Age  Gender\n",
            "0       1  Michael   22    Male\n",
            "1       2   Ashley   65  Female\n",
            "2       3    Holly   26  Female\n",
            "3       4    Traci   29  Female\n",
            "4       5   Wesley   64  Female\n",
            "\n",
            "Cleaned Movies Data:\n",
            "   MovieID                     Title     Genre  ReleaseYear\n",
            "0        1               Region goal    Sci-Fi         1992\n",
            "1        2           Certainly group  Thriller         1996\n",
            "2        3                Goal issue   Romance         2014\n",
            "3        4              Easy explain     Crime         2013\n",
            "4        5  Nearly fire sound method    Comedy         2006\n",
            "\n",
            "Cleaned Ratings Data:\n",
            "   RatingID  UserID  MovieID  Rating                   Timestamp\n",
            "0         1      79       81       1  2021-04-19 03:18:31.839656\n",
            "1         2       5       10       2  2022-07-30 06:16:41.788621\n",
            "2         3      35       49       3  2022-06-20 21:35:50.899465\n",
            "3         4      94       50       3  2021-06-28 06:25:36.359843\n",
            "4         5      85       87       1  2023-12-15 19:54:22.286025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_highest_rated_movies(movies_df, ratings_df):\n",
        "    \"\"\"\n",
        "    Finds the highest-rated movies based on average ratings.\n",
        "\n",
        "    Parameters:\n",
        "        movies_df (pd.DataFrame): DataFrame containing movie information with columns ['MovieID', 'Title'].\n",
        "        ratings_df (pd.DataFrame): DataFrame containing ratings with columns ['MovieID', 'Rating'].\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing the highest-rated movies with their average ratings.\n",
        "    \"\"\"\n",
        "    # Calculate the average rating for each movie\n",
        "    avg_ratings = ratings_df.groupby('MovieID')['Rating'].mean().reset_index()\n",
        "    avg_ratings.rename(columns={'Rating': 'AverageRating'}, inplace=True)\n",
        "\n",
        "    # Merge with the movies DataFrame to get movie titles\n",
        "    highest_rated = pd.merge(avg_ratings, movies_df, on='MovieID')\n",
        "\n",
        "    # Sort by AverageRating in descending order\n",
        "    highest_rated = highest_rated.sort_values(by='AverageRating', ascending=False)\n",
        "\n",
        "    return highest_rated\n",
        "\n",
        "# Process data to find the highest-rated movies\n",
        "highest_rated_movies = find_highest_rated_movies(movies_df, ratings_df)\n",
        "\n",
        "# Display the results\n",
        "print(\"Top Rated Movies:\")\n",
        "print(highest_rated_movies.head(10))  # Display the top 10 highest-rated movies\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdRg5i-f47VY",
        "outputId": "67f59354-5d2c-4772-de77-7e00658fee9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Rated Movies:\n",
            "    MovieID  AverageRating                     Title     Genre  ReleaseYear\n",
            "58      100            5.0              Leader maybe  Thriller         2017\n",
            "43       78            5.0     Than statement family    Sci-Fi         1982\n",
            "21       39            5.0      Across serve include  Thriller         2019\n",
            "1         4            5.0              Easy explain     Crime         2013\n",
            "24       46            5.0                Quite real     Drama         2011\n",
            "42       77            5.0            Investment act    Comedy         1981\n",
            "35       63            5.0            Although learn   Musical         2000\n",
            "5        12            5.0                  Resource     Crime         2010\n",
            "7        16            4.0            Position blood   Romance         2005\n",
            "10       22            4.0  Individual respond piece     Drama         2006\n"
          ]
        }
      ]
    }
  ]
}